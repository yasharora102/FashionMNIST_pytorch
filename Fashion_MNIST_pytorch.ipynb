{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CT2ZdlaoHFyz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download training data\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data \n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxL1cS-PJ4ZC",
        "outputId": "f42f9c69-a038-428b-cde0-13d9e89075d0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:00<00:00, 116774195.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 11070907.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 63992906.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 24875895.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break\n",
        "\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6mY8-N6KDxe",
        "outputId": "ec70325b-f63d-487b-f2c0-3c5b91154351"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class FashionMNISTCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FashionMNISTCNN, self).__init__()\n",
        "        \n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        \n",
        "        # Batch normalization layers\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        \n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        \n",
        "        # FC layer\n",
        "        self.fc = nn.Linear(128*3*3, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = nn.functional.relu(x)\n",
        "        x = nn.functional.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = nn.functional.relu(x)\n",
        "        x = nn.functional.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        \n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = nn.functional.relu(x)\n",
        "        x = nn.functional.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        \n",
        "        x = x.view(-1, 128*3*3)        \n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "\n",
        "model = FashionMNISTCNN().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbozWQdDKRr-",
        "outputId": "f9a31477-0beb-4852-a11e-6e3da77e31dc"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FashionMNISTCNN(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=1152, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "-VS3145aRHgS"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "X5-zDXmkRLPg"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "-CFMcJuyRQ_4"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLkgR2WxRgGY",
        "outputId": "f5d919c1-370d-407c-9d4b-9d372a00e9c4"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.363889  [   64/60000]\n",
            "loss: 0.535188  [ 6464/60000]\n",
            "loss: 0.286922  [12864/60000]\n",
            "loss: 0.464326  [19264/60000]\n",
            "loss: 0.442908  [25664/60000]\n",
            "loss: 0.570426  [32064/60000]\n",
            "loss: 0.376732  [38464/60000]\n",
            "loss: 0.543369  [44864/60000]\n",
            "loss: 0.524929  [51264/60000]\n",
            "loss: 0.444124  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 85.9%, Avg loss: 0.391906 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.325077  [   64/60000]\n",
            "loss: 0.439511  [ 6464/60000]\n",
            "loss: 0.257630  [12864/60000]\n",
            "loss: 0.433203  [19264/60000]\n",
            "loss: 0.428625  [25664/60000]\n",
            "loss: 0.455253  [32064/60000]\n",
            "loss: 0.437892  [38464/60000]\n",
            "loss: 0.572369  [44864/60000]\n",
            "loss: 0.534039  [51264/60000]\n",
            "loss: 0.314061  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.3%, Avg loss: 0.379274 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.263578  [   64/60000]\n",
            "loss: 0.471952  [ 6464/60000]\n",
            "loss: 0.242730  [12864/60000]\n",
            "loss: 0.448876  [19264/60000]\n",
            "loss: 0.419088  [25664/60000]\n",
            "loss: 0.443712  [32064/60000]\n",
            "loss: 0.383055  [38464/60000]\n",
            "loss: 0.554530  [44864/60000]\n",
            "loss: 0.391666  [51264/60000]\n",
            "loss: 0.314899  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.7%, Avg loss: 0.368810 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.322270  [   64/60000]\n",
            "loss: 0.414082  [ 6464/60000]\n",
            "loss: 0.252575  [12864/60000]\n",
            "loss: 0.364053  [19264/60000]\n",
            "loss: 0.333811  [25664/60000]\n",
            "loss: 0.446435  [32064/60000]\n",
            "loss: 0.394169  [38464/60000]\n",
            "loss: 0.588687  [44864/60000]\n",
            "loss: 0.482853  [51264/60000]\n",
            "loss: 0.354938  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.9%, Avg loss: 0.359372 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.276966  [   64/60000]\n",
            "loss: 0.436306  [ 6464/60000]\n",
            "loss: 0.183388  [12864/60000]\n",
            "loss: 0.474740  [19264/60000]\n",
            "loss: 0.349472  [25664/60000]\n",
            "loss: 0.497040  [32064/60000]\n",
            "loss: 0.381067  [38464/60000]\n",
            "loss: 0.439545  [44864/60000]\n",
            "loss: 0.413284  [51264/60000]\n",
            "loss: 0.330582  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.3%, Avg loss: 0.351206 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.272059  [   64/60000]\n",
            "loss: 0.403995  [ 6464/60000]\n",
            "loss: 0.230579  [12864/60000]\n",
            "loss: 0.393174  [19264/60000]\n",
            "loss: 0.430315  [25664/60000]\n",
            "loss: 0.494303  [32064/60000]\n",
            "loss: 0.323274  [38464/60000]\n",
            "loss: 0.488267  [44864/60000]\n",
            "loss: 0.466868  [51264/60000]\n",
            "loss: 0.326915  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.5%, Avg loss: 0.344210 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.309388  [   64/60000]\n",
            "loss: 0.388259  [ 6464/60000]\n",
            "loss: 0.229242  [12864/60000]\n",
            "loss: 0.419393  [19264/60000]\n",
            "loss: 0.339142  [25664/60000]\n",
            "loss: 0.456495  [32064/60000]\n",
            "loss: 0.374836  [38464/60000]\n",
            "loss: 0.564799  [44864/60000]\n",
            "loss: 0.401345  [51264/60000]\n",
            "loss: 0.312006  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.8%, Avg loss: 0.338495 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.263751  [   64/60000]\n",
            "loss: 0.424258  [ 6464/60000]\n",
            "loss: 0.251347  [12864/60000]\n",
            "loss: 0.398930  [19264/60000]\n",
            "loss: 0.363339  [25664/60000]\n",
            "loss: 0.412023  [32064/60000]\n",
            "loss: 0.325063  [38464/60000]\n",
            "loss: 0.518005  [44864/60000]\n",
            "loss: 0.455773  [51264/60000]\n",
            "loss: 0.296681  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.9%, Avg loss: 0.333405 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.221099  [   64/60000]\n",
            "loss: 0.388810  [ 6464/60000]\n",
            "loss: 0.196758  [12864/60000]\n",
            "loss: 0.388954  [19264/60000]\n",
            "loss: 0.364003  [25664/60000]\n",
            "loss: 0.432544  [32064/60000]\n",
            "loss: 0.328730  [38464/60000]\n",
            "loss: 0.460981  [44864/60000]\n",
            "loss: 0.369250  [51264/60000]\n",
            "loss: 0.272850  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.0%, Avg loss: 0.328589 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.272790  [   64/60000]\n",
            "loss: 0.386175  [ 6464/60000]\n",
            "loss: 0.199445  [12864/60000]\n",
            "loss: 0.362703  [19264/60000]\n",
            "loss: 0.318402  [25664/60000]\n",
            "loss: 0.493519  [32064/60000]\n",
            "loss: 0.350140  [38464/60000]\n",
            "loss: 0.514239  [44864/60000]\n",
            "loss: 0.380159  [51264/60000]\n",
            "loss: 0.284405  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.0%, Avg loss: 0.324923 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.231239  [   64/60000]\n",
            "loss: 0.335551  [ 6464/60000]\n",
            "loss: 0.242490  [12864/60000]\n",
            "loss: 0.324769  [19264/60000]\n",
            "loss: 0.343768  [25664/60000]\n",
            "loss: 0.396417  [32064/60000]\n",
            "loss: 0.314593  [38464/60000]\n",
            "loss: 0.481949  [44864/60000]\n",
            "loss: 0.412327  [51264/60000]\n",
            "loss: 0.314442  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.2%, Avg loss: 0.320272 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.277895  [   64/60000]\n",
            "loss: 0.393024  [ 6464/60000]\n",
            "loss: 0.164672  [12864/60000]\n",
            "loss: 0.349588  [19264/60000]\n",
            "loss: 0.269019  [25664/60000]\n",
            "loss: 0.452592  [32064/60000]\n",
            "loss: 0.268943  [38464/60000]\n",
            "loss: 0.519130  [44864/60000]\n",
            "loss: 0.412704  [51264/60000]\n",
            "loss: 0.258023  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.2%, Avg loss: 0.316863 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.255411  [   64/60000]\n",
            "loss: 0.383099  [ 6464/60000]\n",
            "loss: 0.133278  [12864/60000]\n",
            "loss: 0.371199  [19264/60000]\n",
            "loss: 0.320333  [25664/60000]\n",
            "loss: 0.392448  [32064/60000]\n",
            "loss: 0.410646  [38464/60000]\n",
            "loss: 0.478483  [44864/60000]\n",
            "loss: 0.453050  [51264/60000]\n",
            "loss: 0.251876  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.6%, Avg loss: 0.312713 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.250629  [   64/60000]\n",
            "loss: 0.307699  [ 6464/60000]\n",
            "loss: 0.168028  [12864/60000]\n",
            "loss: 0.365226  [19264/60000]\n",
            "loss: 0.363978  [25664/60000]\n",
            "loss: 0.317619  [32064/60000]\n",
            "loss: 0.319929  [38464/60000]\n",
            "loss: 0.352429  [44864/60000]\n",
            "loss: 0.344265  [51264/60000]\n",
            "loss: 0.250645  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.6%, Avg loss: 0.309730 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.278053  [   64/60000]\n",
            "loss: 0.385694  [ 6464/60000]\n",
            "loss: 0.205912  [12864/60000]\n",
            "loss: 0.278802  [19264/60000]\n",
            "loss: 0.330479  [25664/60000]\n",
            "loss: 0.416796  [32064/60000]\n",
            "loss: 0.341483  [38464/60000]\n",
            "loss: 0.406453  [44864/60000]\n",
            "loss: 0.410968  [51264/60000]\n",
            "loss: 0.269462  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.8%, Avg loss: 0.305818 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.206686  [   64/60000]\n",
            "loss: 0.315704  [ 6464/60000]\n",
            "loss: 0.164527  [12864/60000]\n",
            "loss: 0.344581  [19264/60000]\n",
            "loss: 0.287993  [25664/60000]\n",
            "loss: 0.389941  [32064/60000]\n",
            "loss: 0.292804  [38464/60000]\n",
            "loss: 0.337764  [44864/60000]\n",
            "loss: 0.473540  [51264/60000]\n",
            "loss: 0.270289  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.7%, Avg loss: 0.303841 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.192730  [   64/60000]\n",
            "loss: 0.347959  [ 6464/60000]\n",
            "loss: 0.162947  [12864/60000]\n",
            "loss: 0.342645  [19264/60000]\n",
            "loss: 0.355523  [25664/60000]\n",
            "loss: 0.326078  [32064/60000]\n",
            "loss: 0.283028  [38464/60000]\n",
            "loss: 0.485204  [44864/60000]\n",
            "loss: 0.367642  [51264/60000]\n",
            "loss: 0.257498  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.8%, Avg loss: 0.300817 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.230946  [   64/60000]\n",
            "loss: 0.318241  [ 6464/60000]\n",
            "loss: 0.159947  [12864/60000]\n",
            "loss: 0.295372  [19264/60000]\n",
            "loss: 0.371017  [25664/60000]\n",
            "loss: 0.416976  [32064/60000]\n",
            "loss: 0.349557  [38464/60000]\n",
            "loss: 0.476092  [44864/60000]\n",
            "loss: 0.372177  [51264/60000]\n",
            "loss: 0.256325  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.0%, Avg loss: 0.299273 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.209064  [   64/60000]\n",
            "loss: 0.339824  [ 6464/60000]\n",
            "loss: 0.144723  [12864/60000]\n",
            "loss: 0.375171  [19264/60000]\n",
            "loss: 0.290470  [25664/60000]\n",
            "loss: 0.405995  [32064/60000]\n",
            "loss: 0.304869  [38464/60000]\n",
            "loss: 0.399296  [44864/60000]\n",
            "loss: 0.415634  [51264/60000]\n",
            "loss: 0.277530  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.0%, Avg loss: 0.296171 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.181791  [   64/60000]\n",
            "loss: 0.339091  [ 6464/60000]\n",
            "loss: 0.141202  [12864/60000]\n",
            "loss: 0.283306  [19264/60000]\n",
            "loss: 0.273454  [25664/60000]\n",
            "loss: 0.331447  [32064/60000]\n",
            "loss: 0.282087  [38464/60000]\n",
            "loss: 0.397310  [44864/60000]\n",
            "loss: 0.366252  [51264/60000]\n",
            "loss: 0.249414  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.1%, Avg loss: 0.293604 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hucPJz0TSLrr",
        "outputId": "f6045c78-cc26-41d9-fbf3-c978bd4261cb"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FashionMNISTCNN(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc): Linear(in_features=1152, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(15):\n",
        "    x, y = test_data[i][0], test_data[i][1]\n",
        "    with torch.no_grad():\n",
        "        x = x.unsqueeze(0)\n",
        "        x = x.to(device)\n",
        "        pred = model(x)\n",
        "        predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "        print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMlfOysqSS2b",
        "outputId": "980d9313-193e-4d32-99a3-e6a6283d8ca1"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n",
            "Predicted: \"Pullover\", Actual: \"Pullover\"\n",
            "Predicted: \"Trouser\", Actual: \"Trouser\"\n",
            "Predicted: \"Trouser\", Actual: \"Trouser\"\n",
            "Predicted: \"Shirt\", Actual: \"Shirt\"\n",
            "Predicted: \"Trouser\", Actual: \"Trouser\"\n",
            "Predicted: \"Coat\", Actual: \"Coat\"\n",
            "Predicted: \"Shirt\", Actual: \"Shirt\"\n",
            "Predicted: \"Sandal\", Actual: \"Sandal\"\n",
            "Predicted: \"Sneaker\", Actual: \"Sneaker\"\n",
            "Predicted: \"Coat\", Actual: \"Coat\"\n",
            "Predicted: \"Sandal\", Actual: \"Sandal\"\n",
            "Predicted: \"Sandal\", Actual: \"Sneaker\"\n",
            "Predicted: \"Dress\", Actual: \"Dress\"\n",
            "Predicted: \"Coat\", Actual: \"Coat\"\n"
          ]
        }
      ]
    }
  ]
}